# Aparche Spark
![image](https://user-images.githubusercontent.com/77317312/122644748-cc97f900-d151-11eb-9f8a-d3d8d808cbdf.png)
- *빅데이터처리를 위한 오픈소스 분산처리 플랫폼* 또는 *빅데이터 분산처리 엔진*

## 빅데이터
- 사전적 의미
  - 기존 데이터베이스 관리도구의 능력을 넘어 대량의 정형 또는 데이터베이스의 형태가 아닌 비정형 데이터 집합을 포함한 데이터로부터 가치를 추출하고 결과를 분석하는 기술
- 따라서 기존의 RDBMS로 데이터를 처리하기에 데이터가 급증하며 사진, 동영상 등을 포함하여 대용량의 다양한 데이터를 고속으로 처리해야 하는 환경이 만들어졌다.
- 이를 효율적으로 처리하기 위해 등장한 것이 `빅데이터 분산처리 플랫폼` 이다.
![image](https://user-images.githubusercontent.com/77317312/122644868-5b0c7a80-d152-11eb-9bb5-0578a76e5859.png)

## Hadoop
- 빅데이터 처리 == 하둡(Hadoop)이라 할 정도로, 하둡 에코시스템이 시장을 지배하였다.
- 하둡은 HDFS(Hadoop Distributed File System)라고 불리는, 분산형 파일 시스템을 기반으로 만들어졌다.
- 데이터 처리 시, `HDFS`와 `맵리듀스`라고 불리는 대형 데이터셋 병렬 처리 방식에 시스템 기반으로 만들어졌다.
- Hadoop의 **HDFS가 Disk I/O를 기반**으로 동작한다는 것에 있다.
- **Hadoop의 문제점**
  - 실시간성 데이터에 대한 니즈가 급격하게 증가하면서, 하둡으로 처리하기에는 속도 측면에서 부적합한 상황등이 등장하기 시작하였다.

## Spark
- `Apache Spark`는 **메모리상에서 동작**하기 때문에 **반복적인 처리가 필요한 작업**에서 속도가 **하둡보다 몇배는 빠르다.**
- 이를 통해 **데이터 실시간 스트리밍 처리**라는 니즈를 충족함으로써, 빅데이터 프레임워크 시작을 빠르게 점유해 가고있다.
- **Spark의 문제점**
  - 메모리로 I/O작업을 하여 데이터를 읽고 쓰는 속도는 빠르지만 메모리 용량보다 큰 데이터를 처리할 때 는 과부하가 걸릴 수도 있다

## Hadoop vs Spark ??
- 최근 이러한 경쟁 관계를 넘어 `Hadoop` + `Spark`라는 둘의 연계가 하나의 큰 흐름으로 자리 잡았다.
- 하둡의 Yarn 위에 스파크를 얹고, 실시간성이 필요한 데이터는 스파크로 처리하는 방식
- 대부분의 기업들과 연구단체에서 이와 같은 아키텍처를 구성하여 동작 중에 있다.
#### Spark 구조
![image](https://user-images.githubusercontent.com/77317312/122645143-d4589d00-d153-11eb-8b9f-3b6fc84f4bc1.png)
![image](https://user-images.githubusercontent.com/77317312/122645174-ff42f100-d153-11eb-8e6d-aa58701cce53.png)

- 기본적으로 Scala, JAVA, Python 등의 다양한 언어 기반의 고수준 API 사용이 가능하다.
- Apache Spark는 위와 같이 다양한 컴포넌트와 라이브러리를 지원한다.
  1. SQL의 기능을 담당하는 `Spark SQL`,
  2. 실시간 데이터 처리를 지원하는 `Spark Streaming`,
  3. 여러 머신러닝 기법을 지원하는 `MLlib`등 다양하고 넓은 범위의 라이브러리가 있으며, 지속적으로 확장되고 있다.

- 특히 MLlib는 최근 크게 각광받고 있어, 금융권 등 국내의 데이터 실시간 분석에서 Spark 비율이 압도적으로 높은 추세이다.
- Tensorflow/Pytoch 등을 활용한 딥러닝 정도의 퍼포먼스는 현재 발휘하지 못하지만, 기계학습 분야에서는 충분한 퍼포먼스를 발휘하고있다.

![image](https://user-images.githubusercontent.com/77317312/122645296-b5a6d600-d154-11eb-8861-579e8ac1a2b9.png)
- **Spark Steaming**은 `Kafka`, Hadoop과 연계 가능한 스파크의 확장성 덕분에, 위와 같은 구조로 대부분의 기업에서 활용되고 있다.
- `카프카`, `플럼`, `키네시스`, `TCP 소켓` 등 다양한 경로를 통해 데이터를 입력 받고, map, reduce, window 등의 연산을 통해 데이터를 분석하여 최종적으로 파일시스테므 데이터베이스 등에 적재된다.
