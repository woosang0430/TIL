# 과대적합(Overfitting)
- 일반화 (Generalization)
  - train, test set의 예측 성능이 좋은것
- 과대적합 (Overfitting)
  - train set과 test set의 성능차이가 많이 났을때
  - 모델이 복잡해서
- 과소적합  (Underfitting)
  - train, test set 모두 성능리 안좋을 때
  - 모델이 간단해서
- ![image](https://user-images.githubusercontent.com/77317312/112445438-79045200-8d92-11eb-86cd-bdafa79bcc34.png)

## 1. Overfitting(과대적합)의 원인
- 모델이 너무 복잡한 경우
  -  overfitting을 줄이기 위한 규제 **하이퍼파라미터** 설정
  -  Feature 개수 줄이기
- 데이터의 문제
  - 데이터 전처리를 통해 질 좋은 데이터를 만든다.
  - 데이터를 더 수집(가장 어려운 일)

- graphviz 예제

#graphviz 코드

## 2. Decision Tree 복잡도 제어(규제)
- decision tree 모델을 복잡하게 하는 것은 노드가 너무 많이 만들어 지기 때문
- 규제 하이퍼 파라미터 정의(각 모델에 따라 하이퍼파라미터는 다르다)
  - `max_depyh` : 트리의 최대 깊이를 제한
  - `max_leaf_nodes` : leaf node의 최대개수를 제한
  - `min_sample_leaf` : leaf node가 되기 위한 sample 수 지정
# Gridsearch(그리드 서치)
## 1. 적당한 max_depth 찾기
```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

cancer = load_breast_cancer()
X, y = cancer['data'], cancer['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

train_acc_list = []
test_acc_list = []

for i in range(1, 11):
  tree = DecisionTreeClassifier(max_depth=i, random_state=1)
  tree.fit(X_train, y_train)
  
  pred_train = tree.predict(X_train)
  pred_test = tree.predict(X_test)
  
  train_acc_list.append(accuracy_score(y_train, pred_train))
  test_acc_list.append(accuracy_score(y_test, pred_test))
  
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))
plt.plot(range(1, 11), train_acc_list, label='train acc')
plt.plot(range(1, 11), test_acc_list, label='test acc')
plt.xlabel('max depth')

plt.legend()
plt.grid(True)
plt.show()
```
- output
- ![image](https://user-images.githubusercontent.com/77317312/112606632-c7315800-8e5b-11eb-820a-2974eb7d91d0.png)

## 2. Grid Search를 이용한 하이퍼파라미터 튜닝
- 하이퍼 파라미터(Hyper parameter)
  - 모델을 생성할 때 사용자가 직접 설정하는 값
- 하이퍼 파라미터 튜닝
  - 하이퍼 파라미터의 설정에 따라 모델의 성능이 달라진다.

## 3. 최적의 하이퍼파라미터 찾기
1. GridSearch 사용(전수조사 느낌)
  - `GridSearchCV()`
      - 시도해볼 하이퍼파라미터들을 지정하면 모든 조합에 대해 교차 검증 후 제일 좋은 성능을 내는 조합 찾아준다.
      - 값이 많아지면 시간이 오래걸린다.
2. Random Search 사용(관능검사 느낌)
  - `RandomizedSearchCV()`
      - GridSearch와 동일한 방식이지만 임의의 값을 대힙하여 평가 횟수만 지정해준다.

### 3-1. GridSearchCV 매개변수 및 결과 조회
- 주요 매개변수
  - `estimator` : 모델객체 지정'
  - `params` : 하이퍼파라미터 목록을 dictionary로 전달
  - `scoring` : 평가 지표
  - `cv` : 교차검증시 fold 개수
  - `n_jobs` : 사용할 CPU 코어 개수 (None:1(default), -1: 모든 코어 사용)
- 메소드
  - `fit(X, y)`, `predict(X)`, `predict_proba(X)`
- 결과 조회 변수
  - `cv_results_` : 파라미터 조합별 결과 조회
  - `best_params_` : 가장 좋은 성능을 낸 parameter 조합 조회
  - `best_estimator_` : 가장 좋은 성능을 낸 모델 반환
```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier

X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)

tree = DecisionTreeClassifier()
# 하이퍼파라미터 후보들을 딕셔러니로 지정, 파라미터 : [후보]
# 지정하지 않은 것들은 default 값을 사용
param_grid = dict(
  max_depth=range(1, 11),
  max_leaf_nodes=[3, 5, 7, 9],
  random_state=[1]
)

grid_search = GridSearchCV(tree, # 학습시킬 모델
                          param_grid=param_grid, # 하이퍼파라미터 후보
                          # scoring= 'accuracy', # 평가지표
                          scoring=['accuracy', 'recall', 'precision'], # 평가지표를 여러개 지정시 리스트로
                          refit='accuracy', # 평가지표가 여러개일 때 어떤 지표를 기준으로 best_estimator 선정
                          cv=5, # 교차검증(cross Validation)의 folder개수(몇개로 나눌 것인지)
                          n_jobs]-1)
# 학습
grid_search.fit(X_train, y_train)

# 검증
from sklearn.metrics import accuracy_score

# 성능이 가장 잘나온 하이퍼 파라미터를 가진 모델로 예측
pred_train = grid_seach.predict(X_train)
accuracy_score(y_train, pred_train)
# >> 0.9577464788732394

# 최적의 하이퍼파라미터
grid_seach.best_params_
# >> {'max_depth': 2, 'max_leaf_nodes': 3, 'random_state': 1}

# 최적의 모델
grid_seach.best_estimator_
# >> sklearn.tree._classes.DecisionTreeClassifier

```

### 3-2. RandomizedSearchCV
- 주요 매소드
  - `estimator` : 모델 객체 지정
  - `param_distributions` : 하이퍼파라미터 목록을 dictionary로 전달
  - `n_iter` : 파라미터 검색 횟수
  - `scoring` : 평가 지표
  - `cv` : 교차검증시 fold 개수
  - `n_jobs` : 사용할 CPU 코어 개수
- 메소드
  - `fit(X, y)`, `predict(X)`, `predict_proba(X)`
- 결과 조회 변수
  - `cv_results_` : 파라미터 조합별 결과 조회
  - `best_params_` : 가장 좋은 성능을 낸 parameter 조합 조회
  - `best_estimator_` : 가장 좋은 성능을 낸 모델 반환

# 코드


# 파이프라인(Pipeline)
- 여러 단계의 머신러닝 프로세스 (전처리의 각 단계, 모델생성, 학습) 처리 과정을 설정하여 한번에 처리
- 2가지 방법
> - 변환기들로만 구성
> - 마지막에 추정기를 넣는다.(모델 1개만)
## 1. pipeline 생성
- (이름, 변환기)를 리스트로 묶어서 전달
- 마지막에는 추정기(모델)가 올 수 있다. -- 없어도됨

## 2. pipeline을 이용한 학습
- `pipeline.fit()`
  - 마지막이 추정기일 때 사용
- `pipeline.fit_transform()`
  - 보통 모든 단계가 변환기일 때 사용

# 코드

### 번외. GridSearch에서 Pipelline 사용
- 하이퍼파라미터 지정시 pipeline `'모델이름__하이퍼파라미터'` 형식으로 지정

# 코드

# make_pipeline() 함수를 이용한 파이프라인 생성

# 코드















