# 데이터셋
- **Train 데이터셋 (훈련/학습 데이터셋)**
  - 모델을 학습 시킬 데이터
- **Validation 데이터셋 (검증 데이터셋)**
  - 학습한 모델의 성능 측정을 위한 데이터
- **Test 데이터셋 (평가 데이터셋)**
  - 최종 테스트 데이터

## 1. Hold out
- 데이터셋을 Train set, Validation set, Test set으로 나눔
- `sklearn.model_selection.train_test_split()` 함수 사용
- ![image](https://user-images.githubusercontent.com/77317312/111599429-988bff80-8813-11eb-9ca9-ac5a74b11903.png)
```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Data_set loading
iris = load_iris()
x, y = iris['data'], iris['target']

# train, test data_set 분리
x_train, x_test, y_train, y_test = train_test_split(x, y,
                                                    test_size=0.2,
                                                    stratify=y,
                                                    random_state=1)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,
                                                  test_size=0.2,
                                                  stratify=y,
                                                  random_state=1)

# 모델 생성
tree = DecisionTreeClassifier(max_depth=2, random_state=1) # 하이퍼 파라미터(hyper parameter)

# 모델 train
tree.fit(x_train, y_train)

# 예측 및 검증(validations_set)
pred_train = tree.predict(x_train)
pred_val = tree.predict(x_val)

acc_train = accuracy_score(y_train, pred_train)
acc_val = accuracy_score(y_val, pred_val)

print('train accuracy :', acc_train)
print('validation accuracy :', acc_val)
# Train accuracy : 0.96875
# Validation accuracy : 0.9166666666666666
# val값을 원하는 수치가 나올 때 까지 성능향상(하이퍼파라미터를 만지든 모델을 바꾸든)

# test dataset으로 마지막 평가(검증)
pred_test = tree.predict(x_test)
acc_test = accuracy_score(y_test, pred_test)

print('test accuracy :' acc_test)
# Test accuracy : 0.9333333333333333
```

## Holdout 방식의 단점
- train/test 셋이 어떻게 나눠 지냐에 따라 결과가 달라진다.
- 데이터가 충분하면 단점 x

## 2. K-켭 교차검증 (K-Fold cross validation)
- 데이터 양이 적을 때 사용가능
- 데이터셋을 k개로 나눈 뒤 하나를 검증세트로 나머지를 훈련세트로 하여 모델을 학습시키고 평가
```python
from sklearn.datasets import load_iris
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

import numpy as np

iris = load_iris()
x, y = iris['data'], iris['target']

# 객체를 생성하면서 몇개의 fold로 나눌지 (k값)을 지정
kfold = KFold(n_splits=3)

# kfold.split(나누려는 inputdata) : Generator 반환 => train/test set의 인덱스를 반환
gen = kfold.splot(x)

# train_set, test_set으로 평가한 정확도 저장할 리스트 정의
acc_train_list = []
acc_test_list = []

for train_idx, test_idx in kfold.split(x):
  # 데이터셋 분리
  x_train, y_train = x[train_idx], y[train_idx]
  x_test, y_test = x[test_idx], y[test_idx]
  
  # 모델 생성
  tree = DicisionTreeClassifier(max_depth=2)
  
  # 학습
  tree.fit(x_train, y_train)
  
  # 검증 및 평가 결과 리스트 추가
  pred_train = tree.predict(x_train)
  pred_test = tree.predict(x_test)
  
  acc_train_list.append(accuracy_score(y_train, pred_train))
  acc_test_list.append(accuracy_score(y_test, pred_test))


```









